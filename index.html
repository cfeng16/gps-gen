<!DOCTYPE html>
<html>

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XB3PR2Y1TQ"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-XB3PR2Y1TQ');
    </script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>GPS as a Control Signal for Image Generation</title>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,500,600' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="assets/css/Highlight-Clean.css">
    <link rel="stylesheet" href="assets/css/styles.css">

    <link rel="apple-touch-icon" sizes="180x180" href="">
    <link rel="icon" type="image/png" sizes="32x32" href="">
    <link rel="icon" type="image/png" sizes="16x16" href="">
    <link rel="manifest" href="site.webmanifest">
    <meta name="robots" content="noindex">

    <meta property="og:site_name" content="GPS-gen" />
    <meta property="og:type" content="video.other" />
    <meta property="og:title" content="GPS as a Control Signal for Image Generation" />
    <meta property="og:description" content="GPS as a Control Signal for Image Generation, 2024." />
    <meta property="og:url" content="" />

    <script src="assets/js/video_comparison.js"></script>
    <script type="module" src="https://unpkg.com/@google/model-viewer@2.0.1/dist/model-viewer.min.js"></script>
</head>

<body>
    <div class="highlight-clean" style="padding-bottom: 10px;">
        <div class="container" style="max-width: 1024px; margin-bottom: 20px;">
            <h1 class="text-center"> <img src="static/icons/gps.png" alt="architecture" style="width: 40px; margin-top: -10px;"> 
                <!-- <b>GPS-to-3D</b> -->GPS as a Control Signal for Image Generation
                <img src="static/icons/scene.png" alt="architecture" style="width: 40px;; margin-top: -10px;"><br>
            </h1>
        </div>
        <!-- <div class="container" style="max-width: 600px; margin-bottom: 20px;">
            <div class="row authors">
                <div class="col">
                    <h5 class="text-center"><a class="text-center" href="https://cfeng16.github.io/">Chao Feng<sup>1</sup> </a></h5>
                </div>
                <div class="col">
                    <h5 class="text-center"><a href="https://ificl.github.io/">Ziyang Chen<sup>1</sup></a></h5>
                </div>
                <div class="col">
                    <h5 class="text-center"><a class="text-center" href="https://holynski.org/">Aleksander Holynski<sup>2</sup></a></h5>
                </div>
            </div>
            <div class="row authors">
                <div class="col">
                    <h5 class="text-center"><a class="text-center" href="https://people.eecs.berkeley.edu/~efros/?_ga=2.34033190.646840951.1701552179-2025108177.1697071158">Alexei A. Efros<sup>2</sup></a></h5>
                </div>
                <div class="col">
                    <h5 class="text-center"><a class="text-center" href="https://andrewowens.com/">Andrew Owens<sup>1</sup></a></h5>
                </div>
            </div>
            <div class="row affiliations">
                <div class="col">
                    <h6 class="text-center"><a class="text-center"><sup>1</sup>University of Michigan</a></h6>
                </div>
                <div class="col">
                    <h6 class="text-center"><a class="text-center"><sup>2</sup>UC Berkeley</a></h6>
                </div>
            </div>
        </div> -->
        <div class="buttons" style="margin-top: 8px; margin-bottom: 8px;">
            <a class="btn btn-light" role="button" href="https://drive.google.com/file/d/1QZTwSQAQx3o1XaV_luGaQ3XexyNCjGDw/view?usp=sharing">
                <svg style="width:24px;height:24px;margin-left:-12px;margin-right:12px" viewBox="0 0 24 24">
                    <path fill="currentColor" d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z"></path>
                </svg>Paper
            </a>
            <!-- <a class="btn btn-light disabled border border-dark" aria-disabled="true" role="button" href="#">
                <svg style="visibility:hidden;width:0px;height:24px;margin-left:-12px;margin-right:12px" width="0px" height="24px" viewBox="0 0 375 531">
                    <polygon stroke="#000000" points="0.5,0.866 459.5,265.87 0.5,530.874 "></polygon>
                </svg>
                Project
            </a> -->
            <a class="btn btn-light" role="button" href="">
                <svg xmlns="http://www.w3.org/2000/svg" style="width:24px;height:24px;margin-left:-12px;margin-right:12px" viewBox="0 0 24 24">
                    <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 
                            1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 
                            3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 
                            2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path>
                </svg>
                Code
            </a>
            <!-- <a class="btn btn-light" role="button" href="gallery_0.html">
                <svg style="width:24px;height:24px;margin-left:-12px;margin-right:12px" width="24px" height="24px" viewBox="0 0 375 531">
                    <polygon stroke="#000000" points="0.5,0.866 459.5,265.87 0.5,530.874 "></polygon>
                </svg>
                Gallery (New)
            </a> -->
        </div>
        <!-- <div class="container" style="max-width: 768px;">
            <div class="row authors">
                <div class="col-sm-12">
                    <h5 class="text-center" style="text-align: center">Authors anonymized</h5>
                </div>
            </div>    
        </div> -->
    </div>
    <!-- <hr class="divider" /> -->
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <div style="text-align: center; padding-bottom: 10px;">
                    <h2><strong>New York City (Generation)</strong></h2>
                </div>
            </div>
        </div>
    </div>
    <!-- <div class="container" style="max-width: 768px;">
        <div class="row captioned_videos">
            <div class="col-md-12">
                <h4 style="text-align: center; margin-bottom: 15px;">Generation</h4>
                <center><img src="static/teaser_new.mov" alt="architecture" style="width: 100%"></center>
            </div>
        </div>
    </div> -->
    <table align=center width=80%>
        <tr>
            <td width=100%>
                <center>
                    <video width="800" autoplay loop muted playsinline id="teaser">
                        <source src="static/compressed_video.mp4" type="video/mp4" />
                    </video>
                    <br>
                </center>
            </td>
            <!--
            <td width = 60%>
                <center>
                    
                </center>
            </td>
            -->
        </tr>
    </table>
    <br>



    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <div style="text-align: center; padding-bottom: 10px;">
                    <h2 style="color: black;"><strong>Abstract</strong></h2>
                </div>
    
                <p style="color: black;">
                    We show that the GPS tags within image metadata provide a useful control signal for image generation. We train GPS-to-image models and use them for tasks that require a fine-grained understanding of how images change their appearance throughout a city. In particular, we train a diffusion model to generate images conditioned on both GPS tag and text, and find that the resulting model learns to successfully vary the contents of its generated images using both control signals, such as by creating images that capture the distinctive appearance of different neighborhoods, parks, and landmarks. We also show that GPS conditioning enables us to "lift" 3D models from 2D GPS-to-image models using score distillation sampling, without need for explicit camera pose estimation. Our evaluations suggest that our GPS-conditioned models successfully learn to generate images that vary based on location, and that GPS conditioning improves estimated 3D structure.
                </p>
            </div>
        </div>
    </div>
    <!-- <div class="container" style="max-width: 768px;">
        <div class="row captioned_videos">
            <div class="col-md-12">
                <h4 style="text-align: center; margin-bottom: 15px;">Reference from Google Maps</h4>
                <center><img src="static/1729719071259.jpg" alt="architecture" style="width: 100%"></center>
            </div>
        </div>
    </div> -->

    <!-- <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <div style="text-align: center; padding-bottom: 10px;">
                    <h2><strong>Method</strong></h2>
                </div>
    
                <p>
                    We introduce our method here.  
                    (a) After downloading geotagged photos, we train a GPS-to-image generation model conditioned on GPS tags and text prompts. The trained generative model can produce images using both conditioning signals in a compositional manner. (b) We can also extract 3D models from a landmark-specific GPS-to-image model using score distillation sampling. This diffusion model parameterizes the GPS location by the azimuth with respect to a given landmark's center. <b>+</b> means we concatenate GPS embeddings and text embeddings.
                </p>
            </div>
        </div>
    </div>
    <div class="container" style="max-width: 768px;">
        <div class="row captioned_videos">
            <div class="col-md-12">
                <center><img src="static/method-v2.png" alt="architecture" style="width: 100%"></center>
                <h6 class="caption" style="text-align: left;">(a) GPS-to-image generation &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(b) GPS-to-3D reconstruction
                    </h6>
            </div>
        </div>
    </div> -->

    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <div style="text-align: center; padding-bottom: 10px;">
                    <h2><strong>Qualitative Results for New York City</strong></h2>
                    <!-- <h4 style="text-align: center; margin-bottom: 15px;">Generation</h4> -->
                </div>
    
                <!-- <p>
                    We introduce our method here.  
                    (a) After downloading geotagged photos of a landmark, we train a GPS-to-image generation model. The GPS coordinates are converted into an angular representation, by taking the direction to the center of the scene. This model also takes text conditioning, using the name of the landmark. (b) We reconstruct a NeRF from the GPS-to-image diffusion model using a variation of DreamFusion that conditions the diffusion model on the viewpoint direction. 
                </p> -->
            </div>
        </div>
    </div>
    <div class="container" style="max-width: 768px;">
        <div class="row captioned_videos">
            <div class="col-md-12">
                <center><img src="static/nyc_map_full.png" alt="architecture" style="width: 100%"></center>
                <!-- <h6 class="caption" style="text-align: left";>Our multi-view diffusion model learns a joint prior over 4 different views. 
                        We optimize the UNet during training using real 3D data. During testing (3D generation), it can serve as a multi-view prior for 3D 
                        generation visa Score Distillation Sampling.
                    </h6> -->
            </div>
        </div>
    </div>


    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <div style="text-align: center; padding-bottom: 10px;">
                    <h2><strong>Qualitative Results for Paris</strong></h2>
                    <!-- <h4 style="text-align: center; margin-bottom: 15px;">Generation</h4> -->
                </div>
    
                <!-- <p>
                    We introduce our method here.  
                    (a) After downloading geotagged photos of a landmark, we train a GPS-to-image generation model. The GPS coordinates are converted into an angular representation, by taking the direction to the center of the scene. This model also takes text conditioning, using the name of the landmark. (b) We reconstruct a NeRF from the GPS-to-image diffusion model using a variation of DreamFusion that conditions the diffusion model on the viewpoint direction. 
                </p> -->
            </div>
        </div>
    </div>
    <div class="container" style="max-width: 768px;">
        <div class="row captioned_videos">
            <div class="col-md-12">
                <center><img src="static/paris_map_full.png" alt="architecture" style="width: 100%"></center>
                <!-- <h6 class="caption" style="text-align: left";>Our multi-view diffusion model learns a joint prior over 4 different views. 
                        We optimize the UNet during training using real 3D data. During testing (3D generation), it can serve as a multi-view prior for 3D 
                        generation visa Score Distillation Sampling.
                    </h6> -->
            </div>
        </div>
    </div>



    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <div style="text-align: center; padding-bottom: 10px;">
                    <h2><strong>Average Images</strong></h2>
                    <!-- <h4 style="text-align: center; margin-bottom: 15px;">Generation</h4> -->
                </div>
                <p>
                    We apply our GPS-to-image models to the problem of obtaining images that are representative of a given concept over a large geographic area. Specifically, we generate a single image that has high probability under all GPS locations within a user-specified area, as measured by our diffusion model. To do this, we follow work on compositional generation <a id="ref13back" href="#ref1">[1]</a> and simultaneously estimate noise using a large number of GPS locations and average together the noise vectors during each step of the reverse diffusion process. 
                </p>
    
                <!-- <p>
                    We introduce our method here.  
                    (a) After downloading geotagged photos of a landmark, we train a GPS-to-image generation model. The GPS coordinates are converted into an angular representation, by taking the direction to the center of the scene. This model also takes text conditioning, using the name of the landmark. (b) We reconstruct a NeRF from the GPS-to-image diffusion model using a variation of DreamFusion that conditions the diffusion model on the viewpoint direction. 
                </p> -->
            </div>
        </div>
    </div>
    <div class="container" style="max-width: 768px;">
        <div class="row captioned_videos">
            <div class="col-md-12">
                <center><img src="static/average.png" alt="architecture" style="width: 80%"></center>
                <!-- <h6 class="caption" style="text-align: left";>Our multi-view diffusion model learns a joint prior over 4 different views. 
                        We optimize the UNet during training using real 3D data. During testing (3D generation), it can serve as a multi-view prior for 3D 
                        generation visa Score Distillation Sampling.
                    </h6> -->
            </div>
        </div>
    </div>

    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <div style="text-align: center; padding-bottom: 10px;">
                    <h2><strong>Diffusion Comparison</strong></h2>
                    <!-- <h4 style="text-align: center; margin-bottom: 15px;">Generation</h4> -->
                </div>
    
                <!-- <p>
                    We introduce our method here.  
                    (a) After downloading geotagged photos of a landmark, we train a GPS-to-image generation model. The GPS coordinates are converted into an angular representation, by taking the direction to the center of the scene. This model also takes text conditioning, using the name of the landmark. (b) We reconstruct a NeRF from the GPS-to-image diffusion model using a variation of DreamFusion that conditions the diffusion model on the viewpoint direction. 
                </p> -->
            </div>
        </div>
    </div>
    <div class="container" style="max-width: 768px;">
        <div class="row captioned_videos">
            <div class="col-md-12">
                <center><img src="static/diff_qualitative.png" alt="architecture" style="width: 100%"></center>
                <!-- <h6 class="caption" style="text-align: left";>Our multi-view diffusion model learns a joint prior over 4 different views. 
                        We optimize the UNet during training using real 3D data. During testing (3D generation), it can serve as a multi-view prior for 3D 
                        generation visa Score Distillation Sampling.
                    </h6> -->
            </div>
        </div>
    </div>


    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-sm-12">
                <!-- <div style="text-align: center; padding-bottom: 10px;"> -->
                    <!-- <h2>3D Results ▼</h2> -->
                    <div style="text-align: center; padding-bottom: 10px; cursor: pointer;" onclick="toggle3DResults()">
                        <h2 id="toggle-header"><strong>3D Results [+] (Click to expand)</strong></h2>
                    </div>
            </div>
        </div>
        <div id="results-content" style="display: none;">
        <p>We show GPS-to-3D reconstructs scenes from unordered collections of tourist photos.</p>
        <div class="row text-center"> 
            <div class="col-4">
                <h5>Reference Image</h5>
            </div>
            <div class="col-4">
                <h5>DreamFusion</h5>
            </div>
            <div class="col-4">
                <h5>Ours</h5>
            </div>
        </div>
    
        <div class="row captioned_videos">
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <!-- <video class="video lazy" id="ex1" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;"> -->
                        <!-- <source data-src="static/examples/dragon.mp4" type="video/mp4"></source> -->
                        <img src="static/imgs/Pisa_resized.jpg" alt="dog" style="width: 100%; margin-top: 5.5px;">
                    <!-- </video> -->
                    <!-- <canvas height="752" class="videoMerge" id="ex1Merge" width="1002"></canvas> -->
                </div>
                <h6 class="caption">Leaning Tower of Pisa </h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex2" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/dreamfusion/pisa_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex2Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
            <!-- <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex3" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/italy.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex3Merge" width="1002"></canvas>
                </div>
                <h6 class="caption">Little italian town, hand-painted style</h6>
            </div> -->
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex3" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/ours/pisa_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex3Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
        </div>
        <div class="row captioned_videos">
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <!-- <video class="video lazy" id="ex4" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/additional/ship.mp4" type="video/mp4"></source>
                    </video> -->
                    <!-- <canvas height="752" class="videoMerge" id="ex4Merge" width="1002"></canvas> -->
                    <img src="static/imgs/arc.jpg" alt="dog" style="width: 100%; margin-top: 5.5px;">
                </div>
                <h6 class="caption">Arc de Triomphe</h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex5" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/dreamfusion/arc_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex5Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex9" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/ours/arc_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex9Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
        </div>
        <div class="row captioned_videos">
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <!-- <video class="video lazy" id="ex10" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/additional/ship.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex10Merge" width="1002"></canvas> -->
                    <img src="static/imgs/Stonehenge_resized.jpg" alt="dog" style="width: 100%; margin-top: 5.5px;">
                </div>
                <h6 class="caption">Stonehenge</h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex11" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/dreamfusion/stonehenge_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex11Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex12" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/ours/stonehenge_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex12Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
        </div>
        <div class="row captioned_videos">
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <img src="static/imgs/Space_Needle_resized.jpg" alt="dog" style="width: 100%; margin-top: 5.5px;">
                </div>
                <h6 class="caption">Space Needle</h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex23" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/dreamfusion/needle_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex23Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex24" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/ours/needle_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex24Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
        </div>
        <div class="row captioned_videos">
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <!-- <video class="video lazy" id="ex13" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/additional/ship.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex13Merge" width="1002"></canvas> -->
                    <img src="static/imgs/Liberty_resized.jpg" alt="dog" style="width: 100%; margin-top: 5.5px;">
                </div>
                <h6 class="caption">Statue of Liberty</h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex14" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/dreamfusion/liberty_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex14Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex15" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/ours/liberty_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex15Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
        </div>
        <div class="row captioned_videos">
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <!-- <video class="video lazy" id="ex16" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/additional/ship.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex16Merge" width="1002"></canvas> -->
                    <img src="static/imgs/Washington_Monument_resized.jpg" alt="dog" style="width: 100%; margin-top: 5.5px;">
                </div>
                <h6 class="caption">Washington Monument</h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex17" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/dreamfusion/was_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex17Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex18" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/ours/was_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex18Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
        </div>
        <!-- <div class="row captioned_videos">
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%"> -->
                    <!-- <img src="static/imgs/Temple-of-Heaven.jpg" alt="dog" style="width: 100%; margin-top: 5.5px;">
                </div>
                <h6 class="caption">Temple of Heaven</h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex20" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/dreamfusion/heaven_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex20Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex21" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/ours/heaven_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex21Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
        </div> -->
        <!-- <div class="row captioned_videos">
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <img src="static/imgs/giza_resized.jpeg" alt="dog" style="width: 100%; margin-top: 5.5px;">
                </div>
                <h6 class="caption">Great Sphinx of Giza (Failure case)</h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex26" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/dreamfusion/giza_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex26Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex27" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/ours/giza_merged.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex27Merge" width="1002"></canvas>
                </div>
                <h6 class="caption"></h6>
            </div>
        </div> -->
        <!-- <div class="row captioned_videos">
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex7" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/mrbean.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex7Merge" width="1002"></canvas>
                </div>
                <h6 class="caption">Mr Bean Cartoon doing a T Pose</h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex8" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/pikachu.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex8Merge" width="1002"></canvas>
                </div>
                <h6 class="caption">Pikachu with hat</h6>
            </div>
            <div class="col-4">
                <div class="video-compare-container" style="width: 100%">
                    <video class="video lazy" id="ex9" loop playsinline autoplay muted onplay="resizeAndPlay(this)" style="height: 0px;">
                        <source data-src="static/examples/wolfgirl.mp4" type="video/mp4"></source>
                    </video>
                    <canvas height="752" class="videoMerge" id="ex9Merge" width="1002"></canvas>
                </div>
                <h6 class="caption">girl riding wolf, cute, cartoon, blender</h6>
            </div>
        </div> -->
        <!-- <div class="col-sm-4 my-auto center" style="margin-left:auto; margin-right: auto;">
            <a href="./gallery_0.html" class="btn btn-primary btn-lg btn-search">
                Additional Examples
            </a>
        </div> -->
    </div>
</div>


    <!-- <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-sm-12">
                <h2>Comparison Results</h2>
                <p>We collected 40 prompts from different sources to compare with other text-to-3D methods. A fixed default configuration is used for all prompts without hyper-paramter tuning with <a href="https://github.com/threestudio-project/threestudio">threestudio</a>.</p>
            </div>
        </div>
        <div class="row" style="margin-bottom: 0px;">
            <div class="col-xs-15 compare-title  compare-title-sm">
                <p>Dreamfusion-IF</p>
            </div>
            <div class="col-xs-15 compare-title">
                <p>Magic3D-IF-SD</p>
            </div>
            <div class="col-xs-15 compare-title">
                <p>Text2Mesh-IF</p>
            </div>
            <div class="col-xs-15 compare-title">
                <p>ProlificDreamer</p>
            </div>
            <div class="col-xs-15 compare-title">
                <p>Ours</p>
            </div>
        </div>
        <div class="row captioned_videos" id="res_2" style="margin-top: 0px; margin-bottom: 0px ;">
            <video class="video lazy" loop playsinline autoplay muted style="width: 100%">
                <source data-src="static/merged_results_320/astronaut.mp4" type="video/mp4"></source>
            </video>
            <p class="compare-caption">an astronaut riding a horse</p>
        </div>
        <div class="row captioned_videos" style="margin-top: 0px; margin-bottom: 0px ;">
            <video class="video lazy" loop playsinline autoplay muted style="width: 100%">
                <source data-src="static/merged_results_320/yoda.mp4" type="video/mp4"></source>
            </video>
            <p class="compare-caption">baby yoda in the style of Mormookiee</p>
        </div>
        <div class="row captioned_videos" style="margin-top: 0px; margin-bottom: 0px ;">
            <video class="video lazy" loop playsinline autoplay muted style="width: 100%">
                <source data-src="static/merged_results_320/windmill.mp4" type="video/mp4"></source>
            </video>
            <p class="compare-caption">Handpainted watercolor windmill, hand-painted</p>
        </div>
        <div class="row captioned_videos" style="margin-top: 0px; margin-bottom: 0px ;">
            <video class="video lazy" loop playsinline autoplay muted style="width: 100%">
                <source data-src="static/merged_results_320/helmet.mp4" type="video/mp4"></source>
            </video>
            <p class="compare-caption">Darth Vader helmet, highly detailed</p>
        </div>

        <div class="col-sm-4 my-auto center" style="margin-left: auto; margin-right: auto;">
            <a href="./test_0.html" class="btn btn-primary btn-lg btn-search">
                Full Test Results
            </a>
        </div>
    </div> -->

    <!-- <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-sm-3">
                <img src="static/dreambooth/dog.png" alt="dog" style="width: 100%">
            </div>
            <div class="col-sm-9">
                <h2>MV DreamBooth</h2>
                <p>Like Dreambooth3D, multi-view diffusion model can be trained with few-shot data of the same subject for personalized generation with a much simpler strategy.</p>
                <p><span style="font-weight: 800;">Left:</span> "Photo of a [v] dog"</p>
            </div>
        </div>
        <div class="row captioned_videos">
            <div class="col-6">
                <video class="video lazy" loop playsinline autoplay muted onplay="resizeAndPlay(this)">
                    <source data-src="static/dreambooth/dog_dog.mp4" type="video/mp4"></source>
                </video>
                <h6 class="caption">Photo of a [v] dog</h6>
            </div>
            <div class="col-6">
                <video class="video lazy" loop playsinline autoplay muted onplay="resizeAndPlay(this)">
                    <source data-src="static/dreambooth/dog_jumping.mp4" type="video/mp4"></source>
                </video>
                <h6 class="caption">Photo of a [v] dog jumping</h6>
            </div>
        </div>
        <div class="row captioned_videos">
            <div class="col-6">
                <video class="video lazy" loop playsinline autoplay muted onplay="resizeAndPlay(this)">
                    <source data-src="static/dreambooth/dog_rainbow.mp4" type="video/mp4"></source>
                </video>
                <h6 class="caption">Photo of a [v] dog sitting on a rainbow carpet</h6>
            </div>
            <div class="col-6">
                <video class="video lazy" loop playsinline autoplay muted onplay="resizeAndPlay(this)">
                    <source data-src="static/dreambooth/dog_sleeping.mp4" type="video/mp4"></source>
                </video>
                <h6 class="caption">Photo of a [v] dog sleeping</h6>
            </div>
        </div>
        <div class="col-sm-4 my-auto center" style="margin-left: auto; margin-right: auto;">
            <a href="./gallery_db_0.html" class="btn btn-primary btn-lg btn-search">
                Additional Results
            </a>
        </div>
    </div> -->

    <!-- <hr class="divider" />
    <div class="container meshes" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Mesh exports</h2>
                <p>Our generated NeRF models can be exported to meshes using an algorithm based on marching cubes for easy integration into 3D renderers or modeling software.</p>
            </div>
        </div>
        <div class="row">
            <div class="col-md-6 col-sm-6 my-auto">
                <model-viewer alt="Sweater Frog"
                    src="assets/meshes/sweaterfrog_1step.glb"
                    poster="https://pub-b1f092b6867f4495b8f149d222a3bffe.r2.dev/meshes/sept28/sweaterfrog_1step.jpg"
                    environment-image="https://modelviewer.dev/shared-assets/environments/whipple_creek_regional_park_04_1k.hdr"
                    shadow-intensity="1" exposure="0.3" camera-controls touch-action="pan-y" ar
                    loading="lazy" reveal="manual" id="mesh1"
                    crossorigin="anonymous" style="height: 300px; width: 100%;">
                </model-viewer>
                <div class="controls">
                    <button class="btn btn-primary loads-model" data-controls="mesh1">Load 3D model</button>
                    <p class="caption" title="a DSLR photo of a frog wearing a sweater">[...] a frog wearing a sweater</p>
                </div>
            </div>
            <div class="col-md-6 col-sm-6 my-auto" style="position: relative">
                <model-viewer alt="Scorpion" src="assets/meshes/scorpion_1step.glb"
                    poster="https://pub-b1f092b6867f4495b8f149d222a3bffe.r2.dev/meshes/sept28/scorpion_1step.jpg"
                    environment-image="https://modelviewer.dev/shared-assets/environments/spruit_sunrise_1k_HDR.hdr"
                    shadow-intensity="1" exposure=".5" camera-controls touch-action="pan-y" ar
                    loading="lazy" reveal="manual" id="mesh2"
                    crossorigin="anonymous" style="height: 300px; width: 100%;">
                </model-viewer>
                <div class="controls">
                    <button class="btn btn-primary loads-model" data-controls="mesh2">Load 3D model</button>
                    <p class="caption" title="an iridescent metal scorpion">an iridescent metal scorpion</p>
                </div>
            </div>
        </div>
        <div class="row">
            <div class="col-md-6 col-sm-6 my-auto">
                <model-viewer alt="Packard car"
                    src="assets/meshes/packardcar_1step.glb"
                    poster="https://pub-b1f092b6867f4495b8f149d222a3bffe.r2.dev/meshes/sept28/packardcar_1step.jpg"
                    environment-image="https://modelviewer.dev/shared-assets/environments/whipple_creek_regional_park_04_1k.hdr"
                    shadow-intensity="1" exposure="0.3" camera-controls touch-action="pan-y" ar
                    loading="lazy" reveal="manual" id="mesh3"
                    crossorigin="anonymous" style="height: 300px; width: 100%;">
                </model-viewer>
                <div class="controls">
                    <button class="btn btn-primary loads-model" data-controls="mesh3">Load 3D model</button>
                    <p class="caption" title="a DSLR photo of a classic Packard car">[...] a classic Packard car</p>
                </div>
            </div>
            <div class="col-md-6 col-sm-6 my-auto" style="position: relative">
                <model-viewer alt="Sydney Opera House"
                    src="assets/meshes/sydney_1step.glb"
                    poster="https://pub-b1f092b6867f4495b8f149d222a3bffe.r2.dev/meshes/sept28/sydney_1step.jpg"
                    environment-image="https://modelviewer.dev/shared-assets/environments/moon_1k.hdr"
                    shadow-intensity="1" exposure="0.6" camera-controls touch-action="pan-y" ar
                    loading="lazy" reveal="manual" id="mesh4"
                    crossorigin="anonymous" style="height: 300px; width: 100%;">
                </model-viewer>
                <div class="controls">
                    <button class="btn btn-primary loads-model" data-controls="mesh4">Load 3D model</button>
                    <p class="caption" title="a DSLR photo of [...] Sydney opera house, aerial view">[...] Sydney opera house, aerial view</p>
                </div>
            </div>
        </div>
        <div class="row">
            <div class="col-md-6 col-sm-6 my-auto">
                <model-viewer alt="Croissant"
                    src="assets/meshes/croissant_1step.glb"
                    poster="https://pub-b1f092b6867f4495b8f149d222a3bffe.r2.dev/meshes/sept28/croissant_1step.jpg"
                    environment-image="https://modelviewer.dev/shared-assets/environments/spruit_sunrise_1k_HDR.hdr"
                    shadow-intensity="1" exposure="0.6" camera-controls touch-action="pan-y" ar
                    loading="lazy" reveal="manual" id="mesh5"
                    crossorigin="anonymous" style="height: 300px; width: 100%;">
                </model-viewer>
                <div class="controls">
                    <button class="btn btn-primary loads-model" data-controls="mesh5">Load 3D model</button>
                    <p class="caption" title="a DSLR photo of [...] a delicious croissant">[...] a delicious croissant</p>
                </div>
            </div>
            <div class="col-md-6 col-sm-6 my-auto" style="position: relative">
                <model-viewer alt="A robot holds a human brain" src="assets/meshes/robotholdsbrain_1step.glb"
                    poster="https://pub-b1f092b6867f4495b8f149d222a3bffe.r2.dev/meshes/sept28/robotholdsbrain_1step.jpg"
                    environment-image="https://modelviewer.dev/shared-assets/environments/spruit_sunrise_1k_HDR.hdr"
                    shadow-intensity="1" exposure="0.5" camera-controls touch-action="pan-y" ar
                    loading="lazy" reveal="manual" id="mesh6"
                    crossorigin="anonymous" style="height: 300px; width: 100%;">
                </model-viewer>
                <div class="controls">
                    <button class="btn btn-primary loads-model" data-controls="mesh6">Load 3D model</button>
                    <p class="caption" title="a DSLR photo of a humanoid robot holding a human brain">[...] a humanoid robot holding a human brain</p>
                </div>
            </div>
        </div>
    </div>
    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>How does DreamFusion work?</h2>
                <p>Given a caption, DreamFusion uses a text-to-image generative model called Imagen to optimize a 3D scene. We propose <strong>Score Distillation Sampling (SDS)</strong>, a way to generate samples from a diffusion model by optimizing a loss function. SDS allows us to optimize samples in an arbitrary parameter space, such as a 3D space, as long as we can map back to images differentiably. We use a 3D scene parameterization similar to Neural Radiance Fields, or NeRFs, to define this differentiable mapping. SDS alone produces reasonable scene appearance, but DreamFusion adds additional regularizers and optimization strategies to improve geometry. The resulting trained NeRFs are coherent, with high-quality normals, surface geometry and depth, and are relightable with a Lambertian shading model.</p>
            </div>
        </div>
        <div class="row">
            <div class="col-md-12">
                <video class="video lazy" controls muted poster="https://pub-b1f092b6867f4495b8f149d222a3bffe.r2.dev/dreamfusion_overview.jpg">
                    <source data-src="https://pub-b1f092b6867f4495b8f149d222a3bffe.r2.dev/dreamfusion_overview.mp4" type="video/mp4"></source>
                </video>
            </div>
        </div>
    </div> -->
    <!-- <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Citation</h2>
                <code>
                    @article{feng2024gps,<br>
                    &nbsp; author = {Feng, Chao and Chen, Ziyang and Holynski, Aleksander and Efros, Alexei A and Owens, Andrew},<br>
                    &nbsp; title  = {Generative Mapping by GPS-to-Image Diffusion Models},<br>
                    &nbsp; year   = {2024},<br>
                }</code></div>
        </div>
    </div> -->
    <hr class="divider" />
    <section class="section">
        <div class="container is-max-desktop">
          <!-- Title -->
          <div class="columns is-centered has-text-centered">
            <div class="column is-full-width">
              <h2 class="title is-3">References</h2>
            </div>
          </div>
          
          <!-- Description -->
          <div class="columns is-centered" style="font-size: 0.8rem;">
            <div class="column is-full-width">
              <div class="content has-text-justified">
                <p id="ref1" style="margin-bottom: 0;">
                  [1] Liu et al., "<a href="https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/" target="_blank">
                    Compositional Visual Generation with Composable Diffusion Models</a>", ECCV 2022.
                  <a href="#ref1back">↩</a>
                </p>
              </div>
            </div>
          </div>
        </div>
      </section>

    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <footer>
            <p> Website template code comes from <a href="https://mv-dream.github.io/">MVDream</a> and <a href="https://dreamfusion3d.github.io/">DreamFusion</a>.<br>
            <a href="https://www.flaticon.com/free-icons/location" title="location icons">Location icons created by Freepik -
                Flaticon</a></p>
            
        </footer>
    </div>
    <script src="https://polyfill.io/v3/polyfill.js?features=IntersectionObserver"></script>
    <script src="assets/js/yall.js"></script>
    <script>
        yall(
            {
                observeChanges: true
            }
        );
    </script>
    <script src="assets/js/scripts.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>
    <script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"></script>
    <!-- Import the component -->
    <script>
    function toggle3DResults() {
        const content = document.getElementById('results-content');
        const header = document.getElementById('toggle-header');
        
        if (content.style.display === 'none' || content.style.display === '') {
            content.style.display = 'block';
            header.innerHTML = '<strong>3D Results [-] (Click to collapse)</strong>';
        } else {
            content.style.display = 'none';
            header.innerHTML = '<strong>3D Results [+] (Click to expand)</strong>';
        }
    }
    </script>
</body>

</html>